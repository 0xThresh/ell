
docs todo:


Getting Started.rst

- creating ur first lmp hello world example,
- verbose mode on
- then add depending on another functions
- show doc string system promtp and return string user prompt or returnign a list of messages (ell.user, ell.system, ell.assistant)
- storing and versioning your prompts
    * show adding ell.init(store='./logdir', autocommit=True), explain that it will store all the promtps and their versions in ./logdir/ell.db plus a blob store for iamges and autocomit will use gpt4o-mini to write commit messages automaticlaly between prompt versions, seem ore later
    explain how promtps get stored by computing the lexical closure of the function wrapped with @ell.simple, (this gets the fucniton and all its global free vars it dpeendson including other fucniton's source code)
    * now run the script and show ls ./logdir now has an ell db.
    * show runnign ell-studio --storage_dir ./logdir to open the studio
    * show the prompt in the lmp graph view, and clicking on it image (u can just put placehodlers here)
    * then show modifying the prompt and auto generated commit messages
    (read more about this on versioning)

- what's next
    * @ell.complex (tool usage, structured outputs, multimodality, message api)
    * multimodal (images, videos, audio)
    * api clients & models
    * designing effective language model programs
    * tutorials

    

- visualizing your prompts & invocations using ell studio

@ell.simple .rst

- autodoc doc string
- usage (can be doc string or )

Prompt Versioning .rst
- how to start using it (ell.init(store='.logdir', autocommit=True))
- exampels of it working
- how it works under the hood 
 * lexical closures
 * computing relationship between prompts & tools / other tracked functions
- how it commit messages are automatically generated.

-explain how all invocations are save as well as the prompts


Ell Studio .rst

- how to use it locally
- the lmp graph
- the invocations view
- viewing an individual lmp#

@ell.complex .rst

Tool Usage .rst

Structured Outputs .rst

Multimodality .rst

Message API .rst

API Clients & Models .rst

Configuration .rst

Designing Effective Language Model Programs .rst

Related Work .rst

* why this is better than langchain
* why this is better than langsmith
* why this is better than weave 
* instructor
* why not use the openai api directly? 
    - u can definitely use numpy to do deep learning, but it's not advisable for large apps




Whole tutorials seciton:

RAG
Vector DBs
Agents
Chatbots
